# Appendix A to Part 58—Quality Assurance Requirements for Monitors used in Evaluations of National Ambient Air Quality Standards 






1.1 *Applicability.* (a) This appendix specifies the minimum quality system requirements applicable to SLAMS and other monitor types whose data are intended to be used to determine compliance with the NAAQS (*e.g.,* SPMs, tribal, CASTNET, NCore, industrial, etc.), unless the EPA Regional Administrator has reviewed and approved the monitor for exclusion from NAAQS use and these quality assurance requirements.


(b) Primary quality assurance organizations are encouraged to develop and maintain quality systems more extensive than the required minimums. Additional guidance for the requirements reflected in this appendix can be found in the “Quality Assurance Handbook for Air Pollution Measurement Systems,” Volume II (see reference 10 of this appendix) and at a national level in references 1, 2, and 3 of this appendix.


1.2 *Primary Quality Assurance Organization (PQAO).* A PQAO is defined as a monitoring organization or a group of monitoring organizations or other organization that is responsible for a set of stations that monitors the same pollutant and for which data quality assessments will be pooled. Each criteria pollutant sampler/monitor must be associated with only one PQAO. In some cases, data quality is assessed at the PQAO level.


1.2.1 Each PQAO shall be defined such that measurement uncertainty among all stations in the organization can be expected to be reasonably homogeneous as a result of common factors. Common factors that should be considered in defining PQAOs include:


(a) Operation by a common team of field operators according to a common set of procedures;


(b) Use of a common quality assurance project plan (QAPP) or standard operating procedures;


(c) Common calibration facilities and standards;


(d) Oversight by a common quality assurance organization; and


(e) Support by a common management organization (*i.e.,* state agency) or laboratory.


Since data quality assessments are made and data certified at the PQAO level, the monitoring organization identified as the PQAO will be responsible for the oversight of the quality of data of all monitoring organizations within the PQAO.


1.2.2 Monitoring organizations having difficulty describing its PQAO or in assigning specific monitors to primary quality assurance organizations should consult with the appropriate EPA Regional Office. Any consolidation of monitoring organizations to PQAOs shall be subject to final approval by the appropriate EPA Regional Office.


1.2.3 Each PQAO is required to implement a quality system that provides sufficient information to assess the quality of the monitoring data. The quality system must, at a minimum, include the specific requirements described in this appendix. Failure to conduct or pass a required check or procedure, or a series of required checks or procedures, does not by itself invalidate data for regulatory decision making. Rather, PQAOs and the EPA shall use the checks and procedures required in this appendix in combination with other data quality information, reports, and similar documentation that demonstrate overall compliance with Part 58. Accordingly, the EPA and PQAOs shall use a “weight of evidence” approach when determining the suitability of data for regulatory decisions. The EPA reserves the authority to use or not use monitoring data submitted by a monitoring organization when making regulatory decisions based on the EPA's assessment of the quality of the data. Consensus built validation templates or validation criteria already approved in QAPPs should be used as the basis for the weight of evidence approach.


1.3 *Definitions.*

(a) *Measurement Uncertainty.* A term used to describe deviations from a true concentration or estimate that are related to the measurement process and not to spatial or temporal population attributes of the air being measured.


(b) *Precision.* A measurement of mutual agreement among individual measurements of the same property usually under prescribed similar conditions, expressed generally in terms of the standard deviation.


(c) *Bias.* The systematic or persistent distortion of a measurement process which causes errors in one direction.


(d) *Accuracy.* The degree of agreement between an observed value and an accepted reference value. Accuracy includes a combination of random error (imprecision) and systematic error (bias) components which are due to sampling and analytical operations.


(e) *Completeness.* A measure of the amount of valid data obtained from a measurement system compared to the amount that was expected to be obtained under correct, normal conditions.


(f) *Detection Limit.* The lowest concentration or amount of target analyte that can be determined to be different from zero by a single measurement at a stated level of probability.


1.4 *Measurement Quality Checks.* The measurement quality checks described in section 3 of this appendix shall be reported to AQS and are included in the data required for certification.


1.5 *Assessments and Reports.* Periodic assessments and documentation of data quality are required to be reported to the EPA. To provide national uniformity in this assessment and reporting of data quality for all networks, specific assessment and reporting procedures are prescribed in detail in sections 3, 4, and 5 of this appendix. On the other hand, the selection and extent of the quality assurance and quality control activities used by a monitoring organization depend on a number of local factors such as field and laboratory conditions, the objectives for monitoring, the level of data quality needed, the expertise of assigned personnel, the cost of control procedures, pollutant concentration levels, etc. Therefore, quality system requirements in section 2 of this appendix are specified in general terms to allow each monitoring organization to develop a quality system that is most efficient and effective for its own circumstances while achieving the data quality objectives described in this appendix.


A quality system (reference 1 of this appendix) is the means by which an organization manages the quality of the monitoring information it produces in a systematic, organized manner. It provides a framework for planning, implementing, assessing and reporting work performed by an organization and for carrying out required quality assurance and quality control activities.


2.1 *Quality Management Plans and Quality Assurance Project Plans.* All PQAOs must develop a quality system that is described and approved in quality management plans (QMP) and QAPPs to ensure that the monitoring results:


(a) Meet a well-defined need, use, or purpose (reference 5 of this appendix);


(b) Provide data of adequate quality for the intended monitoring objectives;


(c) Satisfy stakeholder expectations;


(d) Comply with applicable standards specifications;


(e) Comply with statutory (and other legal) requirements; and


(f) Reflect consideration of cost and economics.


2.1.1 The QMP describes the quality system in terms of the organizational structure, functional responsibilities of management and staff, lines of authority, and required interfaces for those planning, implementing, assessing and reporting activities involving environmental data operations (EDO). The QMP must be suitably documented in accordance with EPA requirements (reference 2 of this appendix), and approved by the appropriate Regional Administrator, or his or her representative. The quality system described in the QMP will be reviewed during the systems audits described in section 2.5 of this appendix. Organizations that implement long-term monitoring programs with EPA funds should have a separate QMP document. Smaller organizations, organizations that do infrequent work with the EPA or have monitoring programs of limited size or scope may combine the QMP with the QAPP if approved by, and subject to any conditions of the EPA. Additional guidance on this process can be found in reference 10 of this appendix. Approval of the recipient's QMP by the appropriate Regional Administrator or his or her representative may allow delegation of authority to the PQAOs independent quality assurance function to review and approve environmental data collection activities adequately described and covered under the scope of the QMP and documented in appropriate planning documents (QAPP). Where a PQAO or monitoring organization has been delegated authority to review and approve their QAPP, an electronic copy must be submitted to the EPA region at the time it is submitted to the PQAO/monitoring organization's QAPP approving authority. The QAPP will be reviewed by the EPA during systems audits or circumstances related to data quality. The QMP submission and approval dates for PQAOs/monitoring organizations must be reported to AQS either by the monitoring organization or the EPA Region.


2.1.2 The QAPP is a formal document describing, in sufficient detail, the quality system that must be implemented to ensure that the results of work performed will satisfy the stated objectives. PQAOs must develop QAPPs that describe how the organization intends to control measurement uncertainty to an appropriate level in order to achieve the data quality objectives for the EDO. The quality assurance policy of the EPA requires every EDO to have a written and approved QAPP prior to the start of the EDO. It is the responsibility of the PQAO/monitoring organization to adhere to this policy. The QAPP must be suitably documented in accordance with EPA requirements (reference 3 of this appendix) and include standard operating procedures for all EDOs either within the document or by appropriate reference. The QAPP must identify each PQAO operating monitors under the QAPP as well as generally identify the sites and monitors to which it is applicable either within the document or by appropriate reference. The QAPP submission and approval dates must be reported to AQS either by the monitoring organization or the EPA Region.


2.1.3 The PQAO/monitoring organization's quality system must have adequate resources both in personnel and funding to plan, implement, assess and report on the achievement of the requirements of this appendix and it's approved QAPP.


2.2 *Independence of Quality Assurance.* The PQAO must provide for a quality assurance management function, that aspect of the overall management system of the organization that determines and implements the quality policy defined in a PQAO's QMP. Quality management includes strategic planning, allocation of resources and other systematic planning activities (*e.g.,* planning, implementation, assessing and reporting) pertaining to the quality system. The quality assurance management function must have sufficient technical expertise and management authority to conduct independent oversight and assure the implementation of the organization's quality system relative to the ambient air quality monitoring program and should be organizationally independent of environmental data generation activities.


2.3. *Data Quality Performance Requirements.*

2.3.1 *Data Quality Objectives.* The DQOs, or the results of other systematic planning processes, are statements that define the appropriate type of data to collect and specify the tolerable levels of potential decision errors that will be used as a basis for establishing the quality and quantity of data needed to support the monitoring objectives (reference 5 of this appendix). The DQOs will be developed by the EPA to support the primary regulatory objectives for each criteria pollutant. As they are developed, they will be added to the regulation. The quality of the conclusions derived from data interpretation can be affected by population uncertainty (spatial or temporal uncertainty) and measurement uncertainty (uncertainty associated with collecting, analyzing, reducing and reporting concentration data). This appendix focuses on assessing and controlling measurement uncertainty.


2.3.1.1 *Measurement Uncertainty for Automated and Manual PM*_2.5_*Methods.* The goal for acceptable measurement uncertainty is defined for precision as an upper 90 percent confidence limit for the coefficient of variation (CV) of 10 percent and ±10 percent for total bias.


2.3.1.2 *Measurement Uncertainty for Automated O*_3_*Methods.* The goal for acceptable measurement uncertainty is defined for precision as an upper 90 percent confidence limit for the CV of 7 percent and for bias as an upper 95 percent confidence limit for the absolute bias of 7 percent.


2.3.1.3 *Measurement Uncertainty for Pb Methods.* The goal for acceptable measurement uncertainty is defined for precision as an upper 90 percent confidence limit for the CV of 20 percent and for bias as an upper 95 percent confidence limit for the absolute bias of 15 percent.


2.3.1.4 *Measurement Uncertainty for NO*_2_. The goal for acceptable measurement uncertainty is defined for precision as an upper 90 percent confidence limit for the CV of 15 percent and for bias as an upper 95 percent confidence limit for the absolute bias of 15 percent.


2.3.1.5 *Measurement Uncertainty for SO*_2._ The goal for acceptable measurement uncertainty for precision is defined as an upper 90 percent confidence limit for the CV of 10 percent and for bias as an upper 95 percent confidence limit for the absolute bias of 10 percent.


2.4 *National Performance Evaluation Programs.* The PQAO shall provide for the implementation of a program of independent and adequate audits of all monitors providing data for NAAQS compliance purposes including the provision of adequate resources for such audit programs. A monitoring plan (or QAPP) which provides for PQAO participation in the EPA's National Performance Audit Program (NPAP), the PM_2.5_ Performance Evaluation Program (PM_2.5_-PEP) program and the Pb Performance Evaluation Program (Pb-PEP) and indicates the consent of the PQAO for the EPA to apply an appropriate portion of the grant funds, which the EPA would otherwise award to the PQAO for these QA activities, will be deemed by the EPA to meet this requirement. For clarification and to participate, PQAOs should contact either the appropriate EPA regional quality assurance (QA) coordinator at the appropriate EPA Regional Office location, or the NPAP coordinator at the EPA Air Quality Assessment Division, Office of Air Quality Planning and Standards, in Research Triangle Park, North Carolina. The PQAOs that plan to implement these programs (self-implement) rather than use the federal programs must meet the adequacy requirements found in the appropriate sections that follow, as well as meet the definition of independent assessment that follows.


2.4.1 *Independent assessment.* An assessment performed by a qualified individual, group, or organization that is not part of the organization directly performing and accountable for the work being assessed. This auditing organization must not be involved with the generation of the ambient air monitoring data. An organization can conduct the performance evaluation (PE) if it can meet this definition and has a management structure that, at a minimum, will allow for the separation of its routine sampling personnel from its auditing personnel by two levels of management. In addition, the sample analysis of audit filters must be performed by a laboratory facility and laboratory equipment separate from the facilities used for routine sample analysis. Field and laboratory personnel will be required to meet PE field and laboratory training and certification requirements to establish comparability to federally implemented programs.


2.5 *Technical Systems Audit Program.* Technical systems audits of each PQAO shall be conducted at least every 3 years by the appropriate EPA Regional Office and reported to the AQS. If a PQAO is made up of more than one monitoring organization, all monitoring organizations in the PQAO should be audited within 6 years (two TSA cycles of the PQAO). As an example, if a state has five local monitoring organizations that are consolidated under one PQAO, all five local monitoring organizations should receive a technical systems audit within a 6-year period. Systems audit programs are described in reference 10 of this appendix.


2.6 *Gaseous and Flow Rate Audit Standards.*

2.6.1 Gaseous pollutant concentration standards (permeation devices or cylinders of compressed gas) used to obtain test concentrations for CO, SO_2_, NO, and NO_2_ must be EPA Protocol Gases certified in accordance with one of the procedures given in Reference 4 of this appendix.


2.6.1.1 The concentrations of EPA Protocol Gas standards used for ambient air monitoring must be certified with a 95-percent confidence interval to have an analytical uncertainty of no more than ±2.0 percent (inclusive) of the certified concentration (tag value) of the gas mixture. The uncertainty must be calculated in accordance with the statistical procedures defined in Reference 4 of this appendix.


2.6.1.2 Specialty gas producers advertising certification with the procedures provided in Reference 4 of this appendix and distributing gases as “EPA Protocol Gas” for ambient air monitoring purposes must adhere to the regulatory requirements specified in 40 CFR 75.21(g) or not use “EPA” in any form of advertising. Monitoring organizations must provide information to the EPA on the specialty gas producers they use on an annual basis. PQAOs, when requested by the EPA, must participate in the EPA Ambient Air Protocol Gas Verification Program at least once every 5 years by sending a new unused standard to a designated verification laboratory.


2.6.2 Test concentrations for O_3_ must be obtained in accordance with the ultraviolet photometric calibration procedure specified in appendix D to Part 50 of this chapter and by means of a certified NIST-traceable O_3_ transfer standard. Consult references 7 and 8 of this appendix for guidance on transfer standards for O_3_.


2.6.3 Flow rate measurements must be made by a flow measuring instrument that is NIST-traceable to an authoritative volume or other applicable standard. Guidance for certifying some types of flowmeters is provided in reference 10 of this appendix.


2.7 *Primary Requirements and Guidance.* Requirements and guidance documents for developing the quality system are contained in references 1 through 11 of this appendix, which also contain many suggested procedures, checks, and control specifications. Reference 10 describes specific guidance for the development of a quality system for data collected for comparison to the NAAQS. Many specific quality control checks and specifications for methods are included in the respective reference methods described in Part 50 of this chapter or in the respective equivalent method descriptions available from the EPA (reference 6 of this appendix). Similarly, quality control procedures related to specifically designated reference and equivalent method monitors are contained in the respective operation or instruction manuals associated with those monitors.


This section provides the requirements for PQAOs to perform the measurement quality checks that can be used to assess data quality. Data from these checks are required to be submitted to the AQS within the same time frame as routinely-collected ambient concentration data as described in 40 CFR 58.16. Table A-1 of this appendix provides a summary of the types and frequency of the measurement quality checks that will be described in this section.


3.1. *Gaseous Monitors of SO*_2_*, NO*_2_*, O*_3_*, and CO*.


3.1.1 *One-Point Quality Control (QC) Check for SO*_2,_ NO_2_, O_3_, and CO. (a) A one-point QC check must be performed at least once every 2 weeks on each automated monitor used to measure SO_2_, NO_2_, O_3_ and CO. With the advent of automated calibration systems, more frequent checking is strongly encouraged. See Reference 10 of this appendix for guidance on the review procedure. The QC check is made by challenging the monitor with a QC check gas of known concentration (effective concentration for open path monitors) between the prescribed range of 0.005 and 0.08 parts per million (ppm) for SO_2_, NO_2_, and O_3_, and between the prescribed range of 0.5 and 5 ppm for CO monitors. The QC check gas concentration selected within the prescribed range should be related to the monitoring objectives for the monitor. If monitoring at an NCore site or for trace level monitoring, the QC check concentration should be selected to represent the mean or median concentrations at the site. If the mean or median concentrations at trace gas sites are below the MDL of the instrument the agency can select the lowest concentration in the prescribed range that can be practically achieved. If the mean or median concentrations at trace gas sites are above the prescribed range the agency can select the highest concentration in the prescribed range. An additional QC check point is encouraged for those organizations that may have occasional high values or would like to confirm the monitors' linearity at the higher end of the operational range or around NAAQS concentrations. If monitoring for NAAQS decisions, the QC concentration can be selected at a higher concentration within the prescribed range but should also consider precision points around mean or median monitor concentrations.


(b) Point analyzers must operate in their normal sampling mode during the QC check and the test atmosphere must pass through all filters, scrubbers, conditioners and other components used during normal ambient sampling and as much of the ambient air inlet system as is practicable. The QC check must be conducted before any calibration or adjustment to the monitor.


(c) Open path monitors are tested by inserting a test cell containing a QC check gas concentration into the optical measurement beam of the instrument. If possible, the normally used transmitter, receiver, and as appropriate, reflecting devices should be used during the test, and the normal monitoring configuration of the instrument should be altered as little as possible to accommodate the test cell for the test. However, if permitted by the associated operation or instruction manual, an alternate local light source or an alternate optical path that does not include the normal atmospheric monitoring path may be used. The actual concentration of the QC check gas in the test cell must be selected to produce an effective concentration in the range specified earlier in this section. Generally, the QC test concentration measurement will be the sum of the atmospheric pollutant concentration and the QC test concentration. As such, the result must be corrected to remove the atmospheric concentration contribution. The corrected concentration is obtained by subtracting the average of the atmospheric concentrations measured by the open path instrument under test immediately before and immediately after the QC test from the QC check gas concentration measurement. If the difference between these before and after measurements is greater than 20 percent of the effective concentration of the test gas, discard the test result and repeat the test. If possible, open path monitors should be tested during periods when the atmospheric pollutant concentrations are relatively low and steady.


(d) Report the audit concentration of the QC gas and the corresponding measured concentration indicated by the monitor to AQS. The percent differences between these concentrations are used to assess the precision and bias of the monitoring data as described in sections 4.1.2 (precision) and 4.1.3 (bias) of this appendix.


3.1.2 *Annual performance evaluation for SO*_2_, *NO*_2_, *O*_3_*, or CO*. A performance evaluation must be conducted on each primary monitor once a year. This can be accomplished by evaluating 25 percent of the primary monitors each quarter. The evaluation should be conducted by a trained experienced technician other than the routine site operator.


3.1.2.1 The evaluation is made by challenging the monitor with audit gas standards of known concentration from at least three audit levels. One point must be within two to three times the method detection limit of the instruments within the PQAOs network, the second point will be less than or equal to the 99th percentile of the data at the site or the network of sites in the PQAO or the next highest audit concentration level. The third point can be around the primary NAAQS or the highest 3-year concentration at the site or the network of sites in the PQAO. An additional 4th level is encouraged for those agencies that would like to confirm the monitors' linearity at the higher end of the operational range. In rare circumstances, there may be sites measuring concentrations above audit level 10. Notify the appropriate EPA region and the AQS program in order to make accommodations for auditing at levels above level 10.


3.1.2.2 The standards from which audit gas test concentrations are obtained must meet the specifications of section 2.6.1 of this appendix. The gas standards and equipment used for the performance evaluation must not be the same as the standards and equipment used for one-point QC, calibrations, span evaluations or NPAP.


3.1.2.3 For point analyzers, the evaluation shall be carried out by allowing the monitor to analyze the audit gas test atmosphere in its normal sampling mode such that the test atmosphere passes through all filters, scrubbers, conditioners, and other sample inlet components used during normal ambient sampling and as much of the ambient air inlet system as is practicable.


3.1.2.4 Open-path monitors are evaluated by inserting a test cell containing the various audit gas concentrations into the optical measurement beam of the instrument. If possible, the normally used transmitter, receiver, and, as appropriate, reflecting devices should be used during the evaluation, and the normal monitoring configuration of the instrument should be modified as little as possible to accommodate the test cell for the evaluation. However, if permitted by the associated operation or instruction manual, an alternate local light source or an alternate optical path that does not include the normal atmospheric monitoring path may be used. The actual concentrations of the audit gas in the test cell must be selected to produce effective concentrations in the evaluation level ranges specified in this section of this appendix. Generally, each evaluation concentration measurement result will be the sum of the atmospheric pollutant concentration and the evaluation test concentration. As such, the result must be corrected to remove the atmospheric concentration contribution. The corrected concentration is obtained by subtracting the average of the atmospheric concentrations measured by the open path instrument under test immediately before and immediately after the evaluation test (or preferably before and after each evaluation concentration level) from the evaluation concentration measurement. If the difference between the before and after measurements is greater than 20 percent of the effective concentration of the test gas standard, discard the test result for that concentration level and repeat the test for that level. If possible, open path monitors should be evaluated during periods when the atmospheric pollutant concentrations are relatively low and steady. Also, if the open-path instrument is not installed in a permanent manner, the monitoring path length must be reverified to be within ±3 percent to validate the evaluation since the monitoring path length is critical to the determination of the effective concentration.


3.1.2.5 Report both the evaluation concentrations (effective concentrations for open-path monitors) of the audit gases and the corresponding measured concentration (corrected concentrations, if applicable, for open path monitors) indicated or produced by the monitor being tested to AQS. The percent differences between these concentrations are used to assess the quality of the monitoring data as described in section 4.1.1 of this appendix.


3.1.3 *National Performance Audit Program (NPAP).*

The NPAP is a performance evaluation which is a type of audit where quantitative data are collected independently in order to evaluate the proficiency of an analyst, monitoring instrument or laboratory. Due to the implementation approach used in the program, NPAP provides a national independent assessment of performance while maintaining a consistent level of data quality. Details of the program can be found in reference 11 of this appendix. The program requirements include:


3.1.3.1 Performing audits of the primary monitors at 20 percent of monitoring sites per year, and 100 percent of the sites every 6 years. High-priority sites may be audited more frequently. Since not all gaseous criteria pollutants are monitored at every site within a PQAO, it is not required that 20 percent of the primary monitors for each pollutant receive an NPAP audit each year only that 20 percent of the PQAOs monitoring sites receive an NPAP audit. It is expected that over the 6-year period all primary monitors for all gaseous pollutants will receive an NPAP audit.


3.1.3.2 Developing a delivery system that will allow for the audit concentration gasses to be introduced to the probe inlet where logistically feasible.


3.1.3.3 Using audit gases that are verified against the NIST standard reference methods or special review procedures and validated per the certification periods specified in Reference 4 of this appendix (EPA Traceability Protocol for Assay and Certification of Gaseous Calibration Standards) for CO, SO_2_, and NO_2_ and using O_3_ analyzers that are verified quarterly against a standard reference photometer.


3.1.3.4 As described in section 2.4 of this appendix, the PQAO may elect, on an annual basis, to utilize the federally implemented NPAP program. If the PQAO plans to self-implement NPAP, the EPA will establish training and other technical requirements for PQAOs to establish comparability to federally implemented programs. In addition to meeting the requirements in sections 3.1.3.1 through 3.1.3.3 of this appendix, the PQAO must:


(a) Utilize an audit system equivalent to the federally implemented NPAP audit system and is separate from equipment used in annual performance evaluations.


(b) Perform a whole system check by having the NPAP system tested against an independent and qualified EPA lab, or equivalent.


(c) Evaluate the system with the EPA NPAP program through collocated auditing at an acceptable number of sites each year (at least one for an agency network of five or less sites; at least two for a network with more than five sites).


(d) Incorporate the NPAP in the PQAO's quality assurance project plan.


(e) Be subject to review by independent, EPA-trained personnel.


(f) Participate in initial and update training/certification sessions.


3.1.3.5 OAQPS, in consultation with the relevant EPA Regional Office, may approve the PQAO's plan to self-implement NPAP if the OAQPS determines that the PQAO's self-implementation plan is equivalent to the federal programs and adequate to meet the objectives of national consistency and data quality.


3.2 *PM*_2.5_.


3.2.1 *Flow Rate Verification for PM*_2.5_. A one-point flow rate verification check must be performed at least once every month (each verification minimally separated by 14 days) on each monitor used to measure PM_2.5_. The verification is made by checking the operational flow rate of the monitor. If the verification is made in conjunction with a flow rate adjustment, it must be made prior to such flow rate adjustment. For the standard procedure, use a flow rate transfer standard certified in accordance with section 2.6 of this appendix to check the monitor's normal flow rate. Care should be used in selecting and using the flow rate measurement device such that it does not alter the normal operating flow rate of the monitor. Report the flow rate of the transfer standard and the corresponding flow rate measured by the monitor to AQS. The percent differences between the audit and measured flow rates are used to assess the bias of the monitoring data as described in section 4.2.2 of this appendix (using flow rates in lieu of concentrations).


3.2.2 *Semi-Annual Flow Rate Audit for PM*_2.5_. Audit the flow rate of the particulate monitor twice a year. The two audits should ideally be spaced between 5 and 7 months apart. The EPA strongly encourages more frequent auditing. The audit should (preferably) be conducted by a trained experienced technician other than the routine site operator. The audit is made by measuring the monitor's normal operating flow rate(s) using a flow rate transfer standard certified in accordance with section 2.6 of this appendix. The flow rate standard used for auditing must not be the same flow rate standard used for verifications or to calibrate the monitor. However, both the calibration standard and the audit standard may be referenced to the same primary flow rate or volume standard. Care must be taken in auditing the flow rate to be certain that the flow measurement device does not alter the normal operating flow rate of the monitor. Report the audit flow rate of the transfer standard and the corresponding flow rate measured by the monitor to AQS. The percent differences between these flow rates are used to evaluate monitor performance.


3.2.3 *Collocated Quality Control Sampling Procedures for PM*_2.5_. For each pair of collocated monitors, designate one sampler as the primary monitor whose concentrations will be used to report air quality for the site, and designate the other as the quality control monitor. There can be only one primary monitor at a monitoring site for a given time period.


3.2.3.1 For each distinct monitoring method designation (FRM or FEM) that a PQAO is using for a primary monitor, the PQAO must have 15 percent of the primary monitors of each method designation collocated (values of 0.5 and greater round up); and have at least one collocated quality control monitor (if the total number of monitors is less than three). The first collocated monitor must be a designated FRM monitor.


3.2.3.2 In addition, monitors selected for collocation must also meet the following requirements:


(a) A primary monitor designated as an EPA FRM shall be collocated with a quality control monitor having the same EPA FRM method designation.


(b) For each primary monitor designated as an EPA FEM used by the PQAO, 50 percent of the monitors designated for collocation, or the first if only one collocation is necessary, shall be collocated with a FRM quality control monitor and 50 percent of the monitors shall be collocated with a monitor having the same method designation as the FEM primary monitor. If an odd number of collocated monitors is required, the additional monitor shall be a FRM quality control monitor. An example of the distribution of collocated monitors for each unique FEM is provided below. Table A-2 of this appendix demonstrates the collocation procedure with a PQAO having one type of primary FRM and multiple primary FEMs.


3.2.3.3 Since the collocation requirements are used to assess precision of the primary monitors and there can only be one primary monitor at a monitoring site, a site can only count for the collocation of the method designation of the primary monitor at that site.


3.2.3.4 The collocated monitors should be deployed according to the following protocol:


(a) Fifty percent of the collocated quality control monitors should be deployed at sites with annual average or daily concentrations estimated to be within plus or minus 20 percent of either the annual or 24-hour NAAQS and the remainder at the PQAOs discretion;


(b) If an organization has no sites with annual average or daily concentrations within ±20 percent of the annual NAAQS or 24-hour NAAQS, 50 percent of the collocated quality control monitors should be deployed at those sites with the annual mean concentrations or 24-hour concentrations among the highest for all sites in the network and the remainder at the PQAOs discretion.


(c) The two collocated monitors must be within 4 meters (inlet to inlet) of each other and at least 2 meters apart for flow rates greater than 200 liters/min or at least 1 meter apart for samplers having flow rates less than 200 liters/min to preclude airflow interference. A waiver allowing up to 10 meters horizontal distance and up to 3 meters vertical distance (inlet to inlet) between a primary and collocated sampler may be approved by the Regional Administrator for sites at a neighborhood or larger scale of representation during the annual network plan approval process. Sampling and analytical methodologies must be the consistently implemented for both primary and collocated quality control samplers and for all other samplers in the network.


(d) Sample the collocated quality control monitor on a 1-in-12 day schedule. Report the measurements from both primary and collocated quality control monitors at each collocated sampling site to AQS. The calculations for evaluating precision between the two collocated monitors are described in section 4.2.1 of this appendix.


3.2.4 *PM*_2.5_* Performance Evaluation Program (PEP) Procedures.* The PEP is an independent assessment used to estimate total measurement system bias. These evaluations will be performed under the national performance evaluation program (NPEP) as described in section 2.4 of this appendix or a comparable program. A prescribed number of Performance evaluation sampling events will be performed annually within each PQAO. For PQAOs with less than or equal to five monitoring sites, five valid performance evaluation audits must be collected and reported each year. For PQAOs with greater than five monitoring sites, eight valid performance evaluation audits must be collected and reported each year. A valid performance evaluation audit means that both the primary monitor and PEP audit concentrations are valid and equal to or greater than 2 µg/m3. Siting of the PEP monitor must be consistent with section 3.2.3.4(c) of this appendix. However, any horizontal distance greater than 4 meters and any vertical distance greater than one meter must be reported to the EPA regional PEP coordinator. Additionally for every monitor designated as a primary monitor, a primary quality assurance organization must:


3.2.4.1 Have each method designation evaluated each year; and,


3.2.4.2 Have all FRM and FEM samplers subject to a PEP audit at least once every 6 years, which equates to approximately 15 percent of the monitoring sites audited each year.


3.2.4.3. Additional information concerning the PEP is contained in reference 10 of this appendix. The calculations for evaluating bias between the primary monitor and the performance evaluation monitor for PM_2.5_ are described in section 4.2.5 of this appendix.


3.3*PM*_10_.


3.3.1 *Flow Rate Verification for PM*_10_*Low Volume Samplers (less than 200 liter/minute).* A one-point flow rate verification check must be performed at least once every month (each verification minimally separated by 14 days) on each monitor used to measure PM_10_. The verification is made by checking the operational flow rate of the monitor. If the verification is made in conjunction with a flow rate adjustment, it must be made prior to such flow rate adjustment. For the standard procedure, use a flow rate transfer standard certified in accordance with section 2.6 of this appendix to check the monitor's normal flow rate. Care should be taken in selecting and using the flow rate measurement device such that it does not alter the normal operating flow rate of the monitor. The percent differences between the audit and measured flow rates are reported to AQS and used to assess the bias of the monitoring data as described in section 4.2.2 of this appendix (using flow rates in lieu of concentrations).


3.3.2 *Flow Rate Verification for PM*_10_*High Volume Samplers (greater than 200 liters/minute).* For PM_10_ high volume samplers, the verification frequency is one verification every 90 days (quarter) with 4 in a year. Other than verification frequency, follow the same technical procedure as described in section 3.3.1 of this appendix.


3.3.3 *Semi-Annual Flow Rate Audit for PM*_10_. Audit the flow rate of the particulate monitor twice a year. The two audits should ideally be spaced between 5 and 7 months apart. The EPA strongly encourages more frequent auditing. The audit should (preferably) be conducted by a trained experienced technician other than the routine site operator. The audit is made by measuring the monitor's normal operating flow rate using a flow rate transfer standard certified in accordance with section 2.6 of this appendix. The flow rate standard used for auditing must not be the same flow rate standard used for verifications or to calibrate the monitor. However, both the calibration standard and the audit standard may be referenced to the same primary flow rate or volume standard. Care must be taken in auditing the flow rate to be certain that the flow measurement device does not alter the normal operating flow rate of the monitor. Report the audit flow rate of the transfer standard and the corresponding flow rate measured by the monitor to AQS. The percent differences between these flow rates are used to evaluate monitor performance.


3.3.4 *Collocated Quality Control Sampling Procedures for Manual PM*_10_. Collocated sampling for PM_10_ is only required for manual samplers. For each pair of collocated monitors, designate one sampler as the primary monitor whose concentrations will be used to report air quality for the site and designate the other as the quality control monitor.


3.3.4.1 For manual PM_10_ samplers, a PQAO must:


(a) Have 15 percent of the primary monitors collocated (values of 0.5 and greater round up); and


(b) Have at least one collocated quality control monitor (if the total number of monitors is less than three).


3.3.4.2 The collocated quality control monitors should be deployed according to the following protocol:


(a) Fifty percent of the collocated quality control monitors should be deployed at sites with daily concentrations estimated to be within plus or minus 20 percent of the applicable NAAQS and the remainder at the PQAOs discretion;


(b) If an organization has no sites with daily concentrations within plus or minus 20 percent of the NAAQS, 50 percent of the collocated quality control monitors should be deployed at those sites with the daily mean concentrations among the highest for all sites in the network and the remainder at the PQAOs discretion.


(c) The two collocated monitors must be within 4 meters (inlet to inlet) of each other and at least 2 meters apart for flow rates greater than 200 liters/min or at least 1 meter apart for samplers having flow rates less than 200 liters/min to preclude airflow interference. A waiver allowing up to 10 meters horizontal distance and up to 3 meters vertical distance (inlet to inlet) between a primary and collocated sampler may be approved by the Regional Administrator for sites at a neighborhood or larger scale of representation. This waiver may be approved during the annual network plan approval process. Sampling and analytical methodologies must be the consistently implemented for both collocated samplers and for all other samplers in the network.


(d) Sample the collocated quality control monitor on a 1-in-12 day schedule. Report the measurements from both primary and collocated quality control monitors at each collocated sampling site to AQS. The calculations for evaluating precision between the two collocated monitors are described in section 4.2.1 of this appendix.


(e) In determining the number of collocated quality control sites required for PM_10_, monitoring networks for lead (Pb-PM_10_) should be treated independently from networks for particulate matter (PM), even though the separate networks may share one or more common samplers. However, a single quality control monitor that meets the collocation requirements for Pb-PM_10_ and PM_10_ may serve as a collocated quality control monitor for both networks. Extreme care must be taken when using the filter from a quality control monitor for both PM_10_ and Pb analysis. A PM_10_ filter weighing should occur prior to any Pb analysis.


3.4 *Pb.*

3.4.1 *Flow Rate Verification for Pb-PM*_10_*Low Volume Samplers (less than 200 liter/minute).* A one-point flow rate verification check must be performed at least once every month (each verification minimally separated by 14 days) on each monitor used to measure Pb. The verification is made by checking the operational flow rate of the monitor. If the verification is made in conjunction with a flow rate adjustment, it must be made prior to such flow rate adjustment. For the standard procedure, use a flow rate transfer standard certified in accordance with section 2.6 of this appendix to check the monitor's normal flow rate. Care should be taken in selecting and using the flow rate measurement device such that it does not alter the normal operating flow rate of the monitor. The percent differences between the audit and measured flow rates are reported to AQS and used to assess the bias of the monitoring data as described in section 4.2.2 of this appendix (using flow rates in lieu of concentrations).


3.4.2 *Flow Rate Verification for Pb High Volume Samplers (greater than 200 liters/minute).* For high volume samplers, the verification frequency is one verification every 90 days (quarter) with four in a year. Other than verification frequency, follow the same technical procedure as described in section 3.4.1 of this appendix.


3.4.3 *Semi-Annual Flow Rate Audit for Pb.* Audit the flow rate of the particulate monitor twice a year. The two audits should ideally be spaced between 5 and 7 months apart. The EPA strongly encourages more frequent auditing. The audit should (preferably) be conducted by a trained experienced technician other than the routine site operator. The audit is made by measuring the monitor's normal operating flow rate using a flow rate transfer standard certified in accordance with section 2.6 of this appendix. The flow rate standard used for auditing must not be the same flow rate standard used for verifications or to calibrate the monitor. However, both the calibration standard and the audit standard may be referenced to the same primary flow rate or volume standard. Care must be taken in auditing the flow rate to be certain that the flow measurement device does not alter the normal operating flow rate of the monitor. Report the audit flow rate of the transfer standard and the corresponding flow rate measured by the monitor to AQS. The percent differences between these flow rates are used to evaluate monitor performance.


3.4.4 Collocated Quality Control Sampling for TSP Pb for monitoring sites other than non-source oriented NCore. For each pair of collocated monitors for manual TSP Pb samplers, designate one sampler as the primary monitor whose concentrations will be used to report air quality for the site, and designate the other as the quality control monitor.


3.4.4.1 A PQAO must:


(a) Have 15 percent of the primary monitors (not counting non-source oriented NCore sites in PQAO) collocated. Values of 0.5 and greater round up; and


(b) Have at least one collocated quality control monitor (if the total number of monitors is less than three).


3.4.4.2 The collocated quality control monitors should be deployed according to the following protocol:


(a) The first collocated Pb site selected must be the site measuring the highest Pb concentrations in the network. If the site is impractical, alternative sites, approved by the EPA Regional Administrator, may be selected. If additional collocated sites are necessary, collocated sites may be chosen that reflect average ambient air Pb concentrations in the network.


(b) The two collocated monitors must be within 4 meters (inlet to inlet) of each other and at least 2 meters apart for flow rates greater than 200 liters/min or at least 1 meter apart for samplers having flow rates less than 200 liters/min to preclude airflow interference.


(c) Sample the collocated quality control monitor on a 1-in-12 day schedule. Report the measurements from both primary and collocated quality control monitors at each collocated sampling site to AQS. The calculations for evaluating precision between the two collocated monitors are described in section 4.2.1 of this appendix.


3.4.5 Collocated Quality Control Sampling for Pb-PM_10_ at monitoring sites other than non-source oriented NCore. If a PQAO is monitoring for Pb-PM_10_ at sites other than at a non-source oriented NCore site then the PQAO must:


3.4.5.1 Have 15 percent of the primary monitors (not counting non-source oriented NCore sites in PQAO) collocated. Values of 0.5 and greater round up; and


3.4.5.2 Have at least one collocated quality control monitor (if the total number of monitors is less than three).


3.4.5.3 The collocated monitors should be deployed according to the following protocol:


(a) Fifty percent of the collocated quality control monitors should be deployed at sites with the highest 3-month average concentrations and the remainder at the PQAOs discretion.


(b) The two collocated monitors must be within 4 meters (inlet to inlet) of each other and at least 2 meters apart for flow rates greater than 200 liters/min or at least 1 meter apart for samplers having flow rates less than 200 liters/min to preclude airflow interference. A waiver allowing up to 10 meters horizontal distance and up to 3 meters vertical distance (inlet to inlet) between a primary and collocated sampler may be approved by the Regional Administrator for sites at a neighborhood or larger scale of representation. This waiver may be approved during the annual network plan approval process. Sampling and analytical methodologies must be the consistently implemented for both collocated samplers and for all other samplers in the network.


(c) Sample the collocated quality control monitor on a 1-in-12 day schedule. Report the measurements from both primary and collocated quality control monitors at each collocated sampling site to AQS. The calculations for evaluating precision between the two collocated monitors are described in section 4.2.1 of this appendix.


(d) In determining the number of collocated quality control sites required for Pb-PM_10_, monitoring networks for PM_10_ should be treated independently from networks for Pb-PM_10_, even though the separate networks may share one or more common samplers. However, a single quality control monitor that meets the collocation requirements for Pb-PM_10_ and PM_10_ may serve as a collocated quality control monitor for both networks. Extreme care must be taken when using a using the filter from a quality control monitor for both PM_10_ and Pb analysis. A PM_10_ filter weighing should occur prior to any Pb analysis.


3.4.6 *Pb Analysis Audits.* Each calendar quarter, audit the Pb reference or equivalent method analytical procedure using filters containing a known quantity of Pb. These audit filters are prepared by depositing a Pb standard on unexposed filters and allowing them to dry thoroughly. The audit samples must be prepared using batches of reagents different from those used to calibrate the Pb analytical equipment being audited. Prepare audit samples in the following concentration ranges:


(a) Extract the audit samples using the same extraction procedure used for exposed filters.


(b) Analyze three audit samples in each of the two ranges each quarter samples are analyzed. The audit sample analyses shall be distributed as much as possible over the entire calendar quarter.


(c) Report the audit concentrations (in µg Pb/filter or strip) and the corresponding measured concentrations (in µg Pb/filter or strip) to AQS using AQS unit code 077. The percent differences between the concentrations are used to calculate analytical accuracy as described in section 4.2.6 of this appendix.


3.4.7 Pb PEP Procedures for monitoring sites other than non-source oriented NCore. The PEP is an independent assessment used to estimate total measurement system bias. These evaluations will be performed under the NPEP described in section 2.4 of this appendix or a comparable program. Each year, one performance evaluation audit must be performed at one Pb site in each primary quality assurance organization that has less than or equal to five sites and two audits at PQAOs with greater than five sites. Non-source oriented NCore sites are not counted. Siting of the PEP monitor must be consistent with section 3.4.5.3(b). However, any horizontal distance greater than 4 meters and any vertical distance greater than 1 meter must be reported to the EPA regional PEP coordinator. In addition, each year, four collocated samples from PQAOs with less than or equal to five sites and six collocated samples at PQAOs with greater than five sites must be sent to an independent laboratory, the same laboratory as the performance evaluation audit, for analysis. The calculations for evaluating bias between the primary monitor and the performance evaluation monitor for Pb are described in section 4.2.4 of this appendix.


(a) Calculations of measurement uncertainty are carried out by the EPA according to the following procedures. The PQAOs must report the data to AQS for all measurement quality checks as specified in this appendix even though they may elect to perform some or all of the calculations in this section on their own.


(b) The EPA will provide annual assessments of data quality aggregated by site and PQAO for SO_2_, NO_2_, O_3_ and CO and by PQAO for PM_10_, PM_2.5_, and Pb.


(c) At low concentrations, agreement between the measurements of collocated quality control samplers, expressed as relative percent difference or percent difference, may be relatively poor. For this reason, collocated measurement pairs are selected for use in the precision and bias calculations only when both measurements are equal to or above the following limits:


(1) Pb: 0.002 µg/m
3 (Methods approved after 3/04/2010, with exception of manual equivalent method EQLA-0813-803).


(2) Pb: 0.02 µg/m
3 (Methods approved before 3/04/2010, and manual equivalent method EQLA-0813-803).


(3) PM_10_ (Hi-Vol): 15 µg/m
3.


(4) PM_10_ (Lo-Vol): 3 µg/m
3.


(5) PM_2.5_: 2 µg/m
3.


4.1 *Statistics for the Assessment of QC Checks for* SO_2,_ NO_2_, O_3_ and CO.


4.1.1 *Percent Difference.* Many of the measurement quality checks start with a comparison of an audit concentration or value (flow rate) to the concentration/value measured by the monitor and use percent difference as the comparison statistic as described in equation 1 of this section. For each single point check, calculate the percent difference, *d*_i_, as follows:


4.1.2 *Precision Estimate.* The precision estimate is used to assess the one-point QC checks for SO_2_, NO_2_, O_3_, or CO described in section 3.1.1 of this appendix. The precision estimator is the coefficient of variation upper bound and is calculated using equation 2 of this section:


4.1.3 *Bias Estimate.* The bias estimate is calculated using the one-point QC checks for SO_2_, NO_2_, O_3_, or CO described in section 3.1.1 of this appendix. The bias estimator is an upper bound on the mean absolute value of the percent differences as described in equation 3 of this section:


4.1.3.1 *Assigning a sign (positive/negative) to the bias estimate.* Since the bias statistic as calculated in equation 3 of this appendix uses absolute values, it does not have a tendency (negative or positive bias) associated with it. A sign will be designated by rank ordering the percent differences of the QC check samples from a given site for a particular assessment interval.


4.1.3.2 Calculate the 25th and 75th percentiles of the percent differences for each site. The absolute bias upper bound should be flagged as positive if both percentiles are positive and negative if both percentiles are negative. The absolute bias upper bound would not be flagged if the 25th and 75th percentiles are of different signs.


4.2 *Statistics for the Assessment of* PM_10,_ PM_2.5_, and Pb.


4.2.1 *Collocated Quality Control Sampler Precision Estimate for PM*_10,_* PM*_2.5_*, and Pb*. Precision is estimated via duplicate measurements from collocated samplers. It is recommended that the precision be aggregated at the PQAO level quarterly, annually, and at the 3-year level. The data pair would only be considered valid if both concentrations are greater than or equal to the minimum values specified in section 4(c) of this appendix. For each collocated data pair, calculate *t*_i_*,* using equation 6 to this appendix:


Where *X*_i_ is the concentration from the primary sampler and *Y*_i_ is the concentration value from the audit sampler. The coefficient of variation upper bound is calculated using equation 7 to this appendix:


Where *k* is the number of valid data pairs being aggregated, and X
2_0.1,k-1_ is the 10th percentile of a chi-squared distribution with k-1 degrees of freedom. The factor of 2 in the denominator adjusts for the fact that each *t*_i_ is calculated from two values with error.


4.2.2 *One-Point Flow Rate Verification Bias Estimate for**PM*_10,_*PM*_2.5_*and Pb*. For each one-point flow rate verification, calculate the percent difference in volume using equation 1 of this appendix where *meas* is the value indicated by the sampler's volume measurement and *audit* is the actual volume indicated by the auditing flow meter. The absolute volume bias upper bound is then calculated using equation 3, where *n* is the number of flow rate audits being aggregated; t_0.95,n-1_ is the 95th quantile of a t-distribution with n-1 degrees of freedom, the quantity *AB* is the mean of the absolute values of the *d*_i′s_ and is calculated using equation 4 of this appendix, and the quantity *AS* in equation 3 of this appendix is the standard deviation of the absolute values if the *d*_i′s_ and is calculated using equation 5 of this appendix.


4.2.3 *Semi-Annual Flow Rate Audit Bias Estimate for**PM*_10,_*PM*_2.5_*and Pb.* Use the same procedure described in section 4.2.2 for the evaluation of flow rate audits.


4.2.4 *Performance Evaluation Programs Bias Estimate for Pb.* The Pb bias estimate is calculated using the paired routine and the PEP monitor as described in section 3.4.7. Use the same procedures as described in section 4.1.3 of this appendix.


4.2.5 *Performance Evaluation Programs Bias Estimate for PM*_2.5_. The bias estimate is calculated using the PEP audits described in section 3.2.4. of this appendix. The bias estimator is based on, s_i_, the absolute difference in concentrations divided by the square root of the PEP concentration.


4.2.6 *Pb**Analysis Audit Bias Estimate.* The bias estimate is calculated using the analysis audit data described in section 3.4.6. Use the same bias estimate procedure as described in section 4.1.3 of this appendix.


5.1 *Reporting Requirements.* For each pollutant, prepare a list of all monitoring sites and their AQS site identification codes in each PQAO and submit the list to the appropriate EPA Regional Office, with a copy to AQS. Whenever there is a change in this list of monitoring sites in a PQAO, report this change to the EPA Regional Office and to AQS.


5.1.1 *Quarterly Reports.* For each quarter, each PQAO shall report to AQS directly (or via the appropriate EPA Regional Office for organizations not direct users of AQS) the results of all valid measurement quality checks it has carried out during the quarter. The quarterly reports must be submitted consistent with the data reporting requirements specified for air quality data as set forth in 40 CFR 58.16. The EPA strongly encourages early submission of the quality assurance data in order to assist the PQAOs ability to control and evaluate the quality of the ambient air data.


5.1.2 *Annual Reports.*

5.1.2.1 When the PQAO has certified relevant data for the calendar year, the EPA will calculate and report the measurement uncertainty for the entire calendar year.


(1) American National Standard Institute—Quality Management Systems For Environmental Information And Technology Programs—Requirements With Guidance For Use. ASQ/ANSI E4-2014. February 2014. Available from ANSI Webstore *https://webstore.ansi.org/.*

(2) EPA Requirements for Quality Management Plans. EPA QA/R-2. EPA/240/B-01/002. March 2001, Reissue May 2006. Office of Environmental Information, Washington DC 20460. *http://www.epa.gov/quality/agency-wide-quality-system-documents.*

(3) EPA Requirements for Quality Assurance Project Plans for Environmental Data Operations. EPA QA/R-5. EPA/240/B-01/003. March 2001, Reissue May 2006. Office of Environmental Information, Washington DC 20460. *http://www.epa.gov/quality/agency-wide-quality-system-documents.*

(4) EPA Traceability Protocol for Assay and Certification of Gaseous Calibration Standards. EPA-600/R-12/531. May, 2012. Available from U.S. Environmental Protection Agency, National Risk Management Research Laboratory, Research Triangle Park NC 27711. *https://www.epa.gov/nscep.*

(5) Guidance for the Data Quality Objectives Process. EPA QA/G-4. EPA/240/B-06/001. February, 2006. Office of Environmental Information, Washington DC 20460. *http://www.epa.gov/quality/agency-wide-quality-system-documents.*

(6) List of Designated Reference and Equivalent Methods. Available from U.S. Environmental Protection Agency, Center for Environmental Measurements and Modeling, Air Methods and Characterization Division, MD-D205-03, Research Triangle Park, NC 27711. *https://www.epa.gov/amtic/air-monitoring-methods-criteria-pollutants.*

(7) Transfer Standards for the Calibration of Ambient Air Monitoring Analyzers for Ozone. EPA-454/B-13-004 U.S. Environmental Protection Agency, Research Triangle Park, NC 27711, October, 2013. *https://www.epa.gov/sites/default/files/2020-09/documents/ozonetransferstandardguidance.pdf.*

(8) Paur, R.J. and F.F. McElroy. Technical Assistance Document for the Calibration of Ambient Ozone Monitors. EPA-600/4-79-057. U.S. Environmental Protection Agency, Research Triangle Park, NC 27711, September, 1979. 

*http://www.epa.gov/ttn/amtic/cpreldoc.html.*

(9) Quality Assurance Handbook for Air Pollution Measurement Systems, Volume 1—A Field Guide to Environmental Quality Assurance. EPA-600/R-94/038a. April 1994. Available from U.S. Environmental Protection Agency, ORD Publications Office, Center for Environmental Research Information (CERI), 26 W. Martin Luther King Drive, Cincinnati, OH 45268. *https://www.epa.gov/amtic/ambient-air-monitoring-quality-assurance#documents.*

(10) Quality Assurance Handbook for Air Pollution Measurement Systems, Volume II: Ambient Air Quality Monitoring Program Quality System Development. EPA-454/B-13-003. *https://www.epa.gov/amtic/ambient-air-monitoring-quality-assurance#documents.*

(11) National Performance Evaluation Program Standard Operating Procedures. *https://www.epa.gov/amtic/ambient-air-monitoring-quality-assurance#npep.*


---

[N] [81 FR 17280, Mar. 28, 2016, as amended at 89 FR 16390, Mar. 6, 2024; 89 FR 103655, Dec. 19, 2024]





